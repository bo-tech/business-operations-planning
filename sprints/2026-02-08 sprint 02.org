* Sprint 2: Testing Foundation for demo-ops

Started: 2026-02-08

** Plan

- [X] Prepare a suitable test host (Linux, KVM)
- [X] Boot ~demo-ops~ dev config in QEMU on the test host, verify SSH works manually
  - [X] Build custom NixOS installer ISO with SSH key
  - [X] Transfer ISO to test host
  - [X] Boot QEMU VM on ~br0~, verify installer gets DHCP address
  - [X] Adjust ~dev.nix~ to static IP (10.10.10.210), add serial console
  - [X] Run ~nixos-anywhere~ to deploy ~demo-ops#dev~ into the VM
  - [X] Verify SSH to deployed system works
  - [X] Run full ansible flow (re-create-machines + bootstrap)
  - [X] Verify k0s cluster operational (kubectl shows pods)
- [X] Review nixos testing, it seems to provide 80% of what is needed
  - it does, start with this and delay looking further into other options for now
- [X] Review existing infrastructure testing tooling (testinfra, labgrid, goss, etc.)
  - skip, only do when needed
- [X] Set up pytest project skeleton with nix devShell
  - not needed anymore
- [X] Write QEMU VM lifecycle wrapper (start, wait for SSH, stop)
  - not needed anymore
- [X] Write first pytest test: boot VM, assert SSH connection works
  - not needed anymore
- [X] run existing ~k0s-nix~ tests to verify it all works
  - it does, better than anticipated. Cross system back and forth, just works.
- [X] Decide where the test code lives (~demo-ops~, separate repo, or ~business-operations~)
- [ ] Test case to bring up a single machine cluster
  - [ ] Scaffold test case, "hello world" like check
  - [ ] k0s is starting
  - [ ] containers are starting
    - Challenge: Needs the images, no network access in a sandboxed environment.
  - [ ] Ansible based bootstrap, e.g. Cilium and OpenEBS are installed and working
    - Also depends on container images
  - [ ] Ansible based machine creation
    - This would run ~nixos-anywhere~ into the test machine, tricky.
- [ ] Document how to trigger test runs with examples
- [ ] review - Build NixOS installer ISO with test SSH key baked in
  - unclear if still needed currently
- [ ] review - Improve key generation handling in ~demo-ops~ (pulled from backlog)
  - unclear if still needed at the moment, may go back into backlog

** Focus

Prove the end-to-end deployment pipeline can be tested automatically
against a QEMU VM.

** Checkpoint

"Can I run a command that deploys ~demo-ops~ into a VM and verifies
Kubernetes is running?"

** Notes

*** Where to put the tests?

**** ~demo-ops~ content

- Hardware configuration for the vm, that's builtin to the testing framework anyway.
- Host configuration, that's easily put inline into the test spec
- Disk layout via disko -> that's tricky, unclear how to do in the testing framework
  - Same time, not needed for every test

Conclusions:

- ~business-operations~ is the right place.

*** Testing related commands

Worked with the `k0s-nix` flake most of the time: https://github.com/johbo/k0s-nix

Documentation sources:

- https://nix.dev/tutorials/nixos/integration-testing-using-virtual-machines.html
- https://nixos.org/manual/nixos/stable/index.html#sec-nixos-tests

**** ~-L~ flag to see the output

This shows the output, or in more general terms the build log.

**** Builder configuration

The builder has to support ~kvm~ and ~nixos~:

#+begin_src text
  # Only run builds with "kvm" and "nixos"
  admin@192.0.2.10 x86_64-linux - 8 1 kvm,nixos-test kvm,nixos-test

  # Also run builds with "kvm" and "nixos"
  admin@192.0.2.10 x86_64-linux - 8 1 kvm,nixos-test
#+end_src

**** Run the tests or "build" the test result

#+begin_src text
  nix build .#checks.x86_64-linux.single -L
  nix build .#checks.aarch64-linux.single -L
#+end_src

Note that this works flawless with remote builders, so from a workstation one
can trigger the test execution on any supported platform if there is a builder
configured.

**** Run on a macos system

This will build a ~aarch64-linux~ system first and needs a builder for this.
Then it will run the test on the macos system via qemu:

#+begin_src text
  nix build .#checks.aarch64-darwin.single -L
#+end_src

When interacting with the test runner this might be interesting. First build the
driver:

#+begin_src text
  nix build .#checks.aarch64-darwin.single.driver
#+end_src

Then run it:

#+begin_src text
  ./result/bin/nixos-test-driver
  ./result/bin/nixos-test-driver --interactive
#+end_src

**** Run a test again, using ~-rebuild~

This only works on the local machine. There is no direct support for remote
builders: https://github.com/NixOS/nix/issues/10451

A workaround is to first copy the derivation and then to build it:

#+begin_src text
  drv=$(nix path-info --derivation .#checks.x86_64-linux.single)
  nix copy --derivation --to ssh-ng://admin@192.0.2.10 .#checks.x86_64-linux.single
  ssh admin@192.0.2.10 nix build "${drv}^out" --rebuild -L
#+end_src


*** Review of NixOS testing

**** Details

- Q: Could it also be used for the disk partitioning part and the OS
  bootstrap?
- Q: How could the test driver be extended?
- Q: Are there other similar approaches in the Nix community available?
- Q: Would it be useful also for steps beyond the base setup?


**** Conclusion

It looks good enough.

There is an extension to run other distributions in the test runner at
https://github.com/numtide/nix-vm-test.

Disk partitioning could be doable, there are installer related tests which may
be worth looking into to learn more.


*** QEMU bridge helper for regular users

QEMU's compiled-in bridge helper points to its own nix store path
(~libexec/qemu-bridge-helper~) which is not setuid. The NixOS setuid
wrapper is at ~/run/wrappers/bin/qemu-bridge-helper~. Running QEMU on
a bridge as a regular user requires passing the wrapper path explicitly:

#+begin_src bash
qemu-system-x86_64 \
  -netdev bridge,id=net0,br=br0,helper=/run/wrappers/bin/qemu-bridge-helper \
  -device virtio-net-pci,netdev=net0 \
  ...
#+end_src

*** QEMU hints with ~-nographic~

- ~Ctrl-a x~ — kill QEMU immediately
- ~Ctrl-a c~ — toggle QEMU monitor console (inspect devices, snapshots,
  ~boot_set~, ~system_reset~, ~info~ commands)
- ~Ctrl-a h~ — show all escape shortcuts
- Boot device: ~-boot d~ = CD-ROM, ~-boot c~ = disk (default). After
  installing, drop the ~-cdrom~ flag or switch to ~-boot c~.
- Serial console: NixOS installed systems don't output to serial by
  default. Add ~boot.kernelParams = [ "console=ttyS0,115200" ];~ to
  get console output with ~-nographic~.

*** UEFI boot required

The disko config uses GPT + ESP (type EF00) with systemd-boot. QEMU
defaults to SeaBIOS (BIOS), which can't boot this. Pass OVMF firmware:

#+begin_src bash
qemu-system-x86_64 \
  -bios /path/to/ovmf/FV/OVMF.fd \
  ...
#+end_src

Install OVMF via ~nix build nixpkgs#OVMF.fd~.

** Learnings and Insights

- Use a static IP outside the DHCP range to avoid lease changes between
  reboots.
- ~nix copy --to ssh://user@host~ may fail with "lacks a signature by a trusted
  key". Use ~root@~ instead. ~trusted-users~ would fix this but grants
  root-equivalent nix store access.
- Full ansible flow (re-create-machines + bootstrap) works in QEMU VM
  including kexec.

** Closing Status
